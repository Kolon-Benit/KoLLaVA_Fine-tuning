{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c9b16eb-ccab-471d-b02f-3d6588e72319",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4631b8-e918-4237-8fa5-b84387ae021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 관련\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# 허깅페이스 관련\n",
    "from huggingface_hub import login\n",
    "from huggingface_hub import create_repo\n",
    "\n",
    "# LLaVA 관련\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.mm_utils import get_model_name_from_path\n",
    "\n",
    "# 기타\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3edc1b5-47f8-4a1a-bd57-40f64f3c5a0a",
   "metadata": {},
   "source": [
    "### 모델 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e0b7af-60d5-4682-b7c5-4d6c28bdc6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"KoLLaVA-1.5v-lora-kolon-v1.2\" # Fine-tuning 된 모델의 Adapter\n",
    "model_base = \"tabtoyou/KoLLaVA-v1.5-Synatra-7b\" # Base 모델\n",
    "\n",
    "model_path = f\"./checkpoints/{model_name}\" # Adapther 경로\n",
    "save_model_path = f\"./checkpoints/merged/{model_name}\" # Adapter가 연결된 최종 LLM 모델의 저장 경로\n",
    "save_model_path_hf = f\"KBNIT/{model_name}\" # 최종 LLM 모델을 저장할 허깅페이스 경로"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570b8132-a267-4a8e-aa57-3519b7f53d56",
   "metadata": {},
   "source": [
    "### Adapter 연결 함수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2640bda-ec5b-484e-bccd-79368e59bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_lora(model_path, model_base, save_model_path):\n",
    "    model_name = get_model_name_from_path(model_path)\n",
    "    tokenizer, model, image_processor, context_len = load_pretrained_model(model_path, model_base, model_name, device_map='cpu')\n",
    "\n",
    "    model.save_pretrained(save_model_path)\n",
    "    tokenizer.save_pretrained(save_model_path)\n",
    "  \n",
    "    login(token = \"토큰을 입력하세요.\") # 허깅페이스 토큰 입력\n",
    "    create_repo(save_model_path_hf) # 허깅페이스 Repository 생성\n",
    "\n",
    "    model.save_pretrained(save_model_path_hf, push_to_hub=True)\n",
    "    tokenizer.save_pretrained(save_model_path_hf, push_to_hub=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d04b29-9f4a-48a7-9974-90946846c72b",
   "metadata": {},
   "source": [
    "### Adapter 연결 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9469426c-b8d9-4ebc-8726-6b339c22adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_lora(model_path, model_base, save_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
